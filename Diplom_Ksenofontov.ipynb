{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nwlamWFUifq8"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import cv2\n",
        "from skimage.transform import resize\n",
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(idx,batch_size):\n",
        "    x = X_train[idx*batch_size:(idx+1)*batch_size]\n",
        "    X_train_array = []\n",
        "    for i in x:\n",
        "        file_name = i\n",
        "        img = plt.imread(file_name,cv2.IMREAD_GRAYSCALE)\n",
        "        if img is not None:\n",
        "            img = resize(img, (800, 800, 1))\n",
        "            img = np.asarray(img)\n",
        "            X_train_array.append(img)\n",
        "    y = Y_train[idx*batch_size:(idx+1)*batch_size]\n",
        "    x, y = np.array(X_train_array), np.array(y)\n",
        "    return (x,y)\n",
        "\n",
        "def batch_generator(batch_size,steps):\n",
        "    idx = 1\n",
        "    while True:\n",
        "        yield load_data(idx-1,batch_size)\n",
        "        if idx < steps:\n",
        "            idx += 1\n",
        "        else:\n",
        "            idx = 1\n",
        "\n",
        "def load_two_dataset(path_one, path_two):\n",
        "  X_dataset_one = []\n",
        "  X_dataset_two = []\n",
        "  fil_array = os.listdir(path_one)\n",
        "  for fil in fil_array:\n",
        "    X_dataset_one.append(path_one + fil)\n",
        "  fil_array = os.listdir(path_two)\n",
        "  for fil in fil_array:\n",
        "    X_dataset_two.append(path_two+fil)\n",
        "  one = 0\n",
        "  two = 0\n",
        "  X_dataset = []\n",
        "  Y_dataset = []\n",
        "  while one + two < len(X_dataset_one) + len(X_dataset_two):\n",
        "    if one < len(X_dataset_one):\n",
        "      X_dataset.append(X_dataset_one[one])\n",
        "      Y_dataset.append(0)\n",
        "      one += 1\n",
        "    if two < len(X_dataset_two):\n",
        "      X_dataset.append(X_dataset_two[two])\n",
        "      Y_dataset.append(1)\n",
        "      two += 1\n",
        "  return (X_dataset, Y_dataset)\n",
        "\n",
        "def load_dataset(path_one, path_two, path_three):\n",
        "  X_dataset_one = []\n",
        "  X_dataset_two = []\n",
        "  X_dataset_three = []\n",
        "  fil_array = os.listdir(path_one)\n",
        "  for fil in fil_array:\n",
        "    X_dataset_one.append(path_one + fil)\n",
        "  fil_array = os.listdir(path_two)\n",
        "  for fil in fil_array:\n",
        "    X_dataset_two.append(path_two+fil)\n",
        "  fil_array = os.listdir(path_three)\n",
        "  for fil in fil_array:\n",
        "    X_dataset_three.append(path_three+fil)\n",
        "  X_dataset = []\n",
        "  Y_dataset = []\n",
        "  one = 0\n",
        "  two = 0\n",
        "  three = 0\n",
        "  while one + two + three<len(X_dataset_one)+len(X_dataset_two) + len(X_dataset_three):\n",
        "    if one < len(X_dataset_one):\n",
        "      X_dataset.append(X_dataset_one[one])\n",
        "      Y_dataset.append([1,0,0])\n",
        "      one += 1\n",
        "    if two < len(X_dataset_two):\n",
        "      X_dataset.append(X_dataset_two[two])\n",
        "      Y_dataset.append([0,1,0])\n",
        "      two += 1\n",
        "    if three < len(X_dataset_three):\n",
        "      X_dataset.append(X_dataset_three[three])\n",
        "      Y_dataset.append([0,0,1])\n",
        "      three += 1\n",
        "  return X_dataset, Y_dataset\n",
        "\n",
        "def load_Test_dataset(X_dataset_paths):\n",
        "  X_test = []\n",
        "  for file in X_dataset_paths:\n",
        "    img = plt.imread(file,cv2.IMREAD_GRAYSCALE)\n",
        "    if img is not None:\n",
        "      img = resize(img,(800,800,1))\n",
        "      img = np.asarray(img)\n",
        "      X_test.append(img)\n",
        "  return X_test\n",
        "\n",
        "def model_tree(example):\n",
        "  exm = resize(example,(1,800,800,1))\n",
        "  P_global = model_global.predict(exm)\n",
        "  if P_global[0][0] > P_global[0][1] and P_global[0][0] > P_global[0][2]:\n",
        "    P_OCT_one = model_OCT_one.predict(exm)\n",
        "    if P_OCT_one[0][0] > P_OCT_one[0][1]:\n",
        "      return 10\n",
        "    else:\n",
        "      P_OCT_two = model_OCT_two.predict(exm)\n",
        "      if P_OCT_two[0][0] > P_OCT_two[0][1] and P_OCT_two[0][0] > P_OCT_two[0][2]:\n",
        "        return 111\n",
        "      elif P_OCT_two[0][1] > P_OCT_two[0][0] and P_OCT_two[0][1] > P_OCT_two[0][2]:\n",
        "        return 112\n",
        "      else:\n",
        "        return 113\n",
        "  elif P_global[0][1] > P_global[0][0] and P_global[0][1] > P_global[0][2]:\n",
        "    P_MRI_one = model_MRI_one.predict(exm)\n",
        "    if P_MRI_one[0][0] > P_MRI_one[0][1]:\n",
        "      return 20\n",
        "    else:\n",
        "      P_MRI_two = model_MRI_two.predict(exm)\n",
        "      if P_MRI_two[0][0] > P_MRI_two[0][1] and P_MRI_two[0][0] > P_MRI_two[0][2]:\n",
        "        return 211\n",
        "      elif P_MRI_two[0][1] > P_MRI_two[0][0] and P_MRI_two[0][1] > P_MRI_two[0][2]:\n",
        "        return 212\n",
        "      else:\n",
        "        return 213\n",
        "  else:\n",
        "    P_XRAY_one = model_XRAY_one.predict(exm)\n",
        "    if P_XRAY_one[0][0] > P_XRAY_one[0][1]:\n",
        "      return 30\n",
        "    else:\n",
        "      P_XRAY_two = model_XRAY_two.predict(exm)\n",
        "      if P_XRAY_two[0][0] > P_XRAY_two[0][1]:\n",
        "        return 311\n",
        "      else:\n",
        "        return 322\n"
      ],
      "metadata": {
        "id": "qUN-Eu5XigZh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/Global_SNS_train.zip"
      ],
      "metadata": {
        "id": "tBwsY8gJilBj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, Y_train = load_dataset('/content/Global_SNS_train/OCT2017/', '/content/Global_SNS_train/MRI/', '/content/Global_SNS_train/Chest/')\n",
        "X_test = np.array(load_Test_dataset(X_train[:143]))\n",
        "Y_test = np.array(Y_train[:143])\n",
        "X_train = X_train[143:]\n",
        "Y_train = Y_train[143:]"
      ],
      "metadata": {
        "id": "2QAZViwjimpB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nd_epochs = 3\n",
        "batch_size = 5\n",
        "size_BD = len(X_train)\n",
        "steps_per_epochs = np.ceil(size_BD/batch_size)\n",
        "my_train_generator = batch_generator(batch_size,steps_per_epochs)\n"
      ],
      "metadata": {
        "id": "FWgGvVRhipMD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_global = Sequential()\n",
        "\n",
        "model_global.add(Conv2D(8,kernel_size=3,activation=\"relu\",input_shape = (800,800,1)))\n",
        "model_global.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model_global.add(Conv2D(16,kernel_size=3,activation=\"relu\"))\n",
        "model_global.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model_global.add(Conv2D(32,kernel_size=3,activation=\"relu\"))\n",
        "model_global.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model_global.add(Conv2D(64,kernel_size=3,activation=\"relu\"))\n",
        "model_global.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model_global.add(Conv2D(128,kernel_size=3,activation=\"relu\"))\n",
        "model_global.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model_global.add(Conv2D(256,kernel_size=3,activation=\"relu\"))\n",
        "model_global.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model_global.add(Flatten())\n",
        "model_global.add(Dense(3,activation=\"softmax\"))"
      ],
      "metadata": {
        "id": "5dPeuSAriquD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_global.compile(optimizer='adamax', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model_global.fit_generator(my_train_generator,steps_per_epoch=steps_per_epochs,epochs=nd_epochs,validation_data=(X_test,Y_test), use_multiprocessing=True)"
      ],
      "metadata": {
        "id": "Cv6aypCvit7x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.clear()\n",
        "Y_train.clear()\n",
        "X_test = []\n",
        "Y_test = []\n",
        "\n",
        "len_test = 100\n",
        "X_train, Y_train = load_two_dataset('/content/SNS_OCT_one/NORMAL/', '/content/SNS_OCT_one/NO/')\n",
        "X_test = np.array(load_Test_dataset(X_train[:len_test]))\n",
        "Y_test = np.array(Y_train[:len_test])\n",
        "X_train = X_train[len_test:]\n",
        "Y_train = Y_train[len_test:]"
      ],
      "metadata": {
        "id": "-Hfe5_vLivxo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nd_epochs = 5\n",
        "batch_size = 5\n",
        "size_BD = len(X_train)\n",
        "steps_per_epochs = np.ceil(size_BD/batch_size)\n",
        "my_train_generator = batch_generator(batch_size,steps_per_epochs)"
      ],
      "metadata": {
        "id": "bJHKTAoMixi_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_OCT_one = Sequential()\n",
        "\n",
        "model_OCT_one.add(Conv2D(8,kernel_size=3,activation=\"relu\",input_shape = (800,800,1)))\n",
        "model_OCT_one.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model_OCT_one.add(Conv2D(16,kernel_size=3,activation=\"relu\"))\n",
        "model_OCT_one.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model_OCT_one.add(Conv2D(32,kernel_size=3,activation=\"relu\"))\n",
        "model_OCT_one.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model_OCT_one.add(Conv2D(64,kernel_size=3,activation=\"relu\"))\n",
        "model_OCT_one.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model_OCT_one.add(Conv2D(128,kernel_size=3,activation=\"relu\"))\n",
        "model_OCT_one.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model_OCT_one.add(Conv2D(256,kernel_size=3,activation=\"relu\"))\n",
        "model_OCT_one.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model_OCT_one.add(Conv2D(512,kernel_size=3,activation=\"relu\"))\n",
        "model_OCT_one.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model_OCT_one.add(Flatten())\n",
        "model_OCT_one.add(Dense(2,activation=\"sigmoid\"))"
      ],
      "metadata": {
        "id": "KvPbtrdgi0Vn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_OCT_one.compile(optimizer='adamax', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model_OCT_one.fit_generator(my_train_generator,steps_per_epoch=steps_per_epochs,epochs=nd_epochs,validation_data=(X_test,Y_test), use_multiprocessing=True)"
      ],
      "metadata": {
        "id": "2v4S0Aq1i2Ce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.clear()\n",
        "Y_train.clear()\n",
        "X_test = []\n",
        "Y_test = []"
      ],
      "metadata": {
        "id": "VYB-6J0zi3MJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/SNS_MRI_one.zip"
      ],
      "metadata": {
        "id": "uCT2KOAAi4aM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len_test = 100\n",
        "X_Normal = []\n",
        "X_no = []\n",
        "path_Normal = \"/content/SNS_MRI_one/NORMAL/\"\n",
        "path_No = '/content/SNS_MRI_one/NO/'\n",
        "fil_array = os.listdir(path_Normal)\n",
        "for fil in fil_array:\n",
        "  X_Normal.append(path_Normal + fil)\n",
        "fil_array = os.listdir(path_No)\n",
        "for fil in fil_array:\n",
        "  X_no.append(path_No + fil)\n",
        "X_train = []\n",
        "Y_train = []\n",
        "normal = 0\n",
        "Not = 0\n",
        "for i in range(len(X_Normal) + len(X_no)):\n",
        "  if i % 6 == 0 and normal < len(X_Normal):\n",
        "    X_train.append(X_Normal[normal])\n",
        "    Y_train.append(0)\n",
        "    normal += 1\n",
        "  else:\n",
        "    X_train.append(X_no[Not])\n",
        "    Y_train.append(1)\n",
        "    Not += 1\n",
        "X_test = np.array(load_Test_dataset(X_train[:len_test]))\n",
        "Y_test = np.array(Y_train[:len_test])\n",
        "X_train = X_train[len_test:]\n",
        "Y_train = Y_train[len_test:]"
      ],
      "metadata": {
        "id": "on9r3hbNi5qc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nd_epochs = 8\n",
        "batch_size = 5\n",
        "size_BD = len(X_train)\n",
        "steps_per_epochs = np.ceil(size_BD/batch_size)\n",
        "my_train_generator = batch_generator(batch_size,steps_per_epochs)"
      ],
      "metadata": {
        "id": "4hrcfz4pi8a8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_MRI_one = Sequential()\n",
        "\n",
        "model_MRI_one.add(Conv2D(8,kernel_size=3,activation=\"relu\",input_shape = (800,800,1)))\n",
        "model_MRI_one.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model_MRI_one.add(Conv2D(16,kernel_size=3,activation=\"relu\"))\n",
        "model_MRI_one.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model_MRI_one.add(Conv2D(32,kernel_size=3,activation=\"relu\"))\n",
        "model_MRI_one.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model_MRI_one.add(Conv2D(64,kernel_size=3,activation=\"relu\"))\n",
        "model_MRI_one.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model_MRI_one.add(Conv2D(128,kernel_size=3,activation=\"relu\"))\n",
        "model_MRI_one.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model_MRI_one.add(Conv2D(256,kernel_size=3,activation=\"relu\"))\n",
        "model_MRI_one.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model_MRI_one.add(Conv2D(512,kernel_size=3,activation=\"relu\"))\n",
        "model_MRI_one.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model_MRI_one.add(Conv2D(1024,kernel_size=3,activation=\"relu\"))\n",
        "model_MRI_one.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model_MRI_one.add(Flatten())\n",
        "model_MRI_one.add(Dense(2,activation=\"sigmoid\"))"
      ],
      "metadata": {
        "id": "ed9coPmXi9h8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_MRI_one.compile(optimizer='adamax', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model_MRI_one.fit_generator(my_train_generator,steps_per_epoch=steps_per_epochs,epochs=nd_epochs,validation_data=(X_test,Y_test), use_multiprocessing=True)"
      ],
      "metadata": {
        "id": "3qC1ggfZi_X0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_no.clear()\n",
        "X_Normal.clear()\n",
        "X_train.clear()\n",
        "Y_train.clear()\n",
        "X_test = []\n",
        "Y_test = []\n",
        "fil_array.clear()"
      ],
      "metadata": {
        "id": "len0FhCnjAdi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/SNS_XRAY_one.zip"
      ],
      "metadata": {
        "id": "DK4ZcidejCBk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len_test = 100\n",
        "X_train, Y_train = load_two_dataset('/content/SNS_XRAY_one/NORMAL/', '/content/SNS_XRAY_one/NO/')\n",
        "X_test = np.array(load_Test_dataset(X_train[:len_test]))\n",
        "Y_test = np.array(Y_train[:len_test])\n",
        "X_train = X_train[len_test:]\n",
        "Y_train = Y_train[len_test:]"
      ],
      "metadata": {
        "id": "1iTQMu-XjDAl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nd_epochs = 4\n",
        "batch_size = 5\n",
        "size_BD = len(X_train)\n",
        "steps_per_epochs = np.ceil(size_BD/batch_size)\n",
        "my_train_generator = batch_generator(batch_size,steps_per_epochs)"
      ],
      "metadata": {
        "id": "HaUcM-YzjEOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_XRAY_one = Sequential()\n",
        "\n",
        "model_XRAY_one.add(Conv2D(8,kernel_size=3,activation=\"relu\",input_shape = (800,800,1)))\n",
        "model_XRAY_one.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model_XRAY_one.add(Conv2D(16,kernel_size=3,activation=\"relu\"))\n",
        "model_XRAY_one.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model_XRAY_one.add(Conv2D(32,kernel_size=3,activation=\"relu\"))\n",
        "model_XRAY_one.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model_XRAY_one.add(Conv2D(64,kernel_size=3,activation=\"relu\"))\n",
        "model_XRAY_one.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model_XRAY_one.add(Conv2D(128,kernel_size=3,activation=\"relu\"))\n",
        "model_XRAY_one.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model_XRAY_one.add(Conv2D(256,kernel_size=3,activation=\"relu\"))\n",
        "model_XRAY_one.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model_XRAY_one.add(Conv2D(512,kernel_size=3,activation=\"relu\"))\n",
        "model_XRAY_one.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model_XRAY_one.add(Flatten())\n",
        "model_XRAY_one.add(Dense(2,activation=\"sigmoid\"))"
      ],
      "metadata": {
        "id": "Of-wu9rEjFec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_XRAY_one.compile(optimizer='adamax', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model_XRAY_one.fit_generator(my_train_generator,steps_per_epoch=steps_per_epochs,epochs=nd_epochs,validation_data=(X_test,Y_test), use_multiprocessing=True)"
      ],
      "metadata": {
        "id": "-GK3CQvyjIOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.clear()\n",
        "Y_train.clear()\n",
        "X_test = []\n",
        "Y_test = []"
      ],
      "metadata": {
        "id": "cUdaMg1OjJVq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/SNS_OCT_two.zip"
      ],
      "metadata": {
        "id": "zEbJXkHnjKO-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len_test = 100\n",
        "X_train, Y_train = load_dataset('/content/SNS_OCT_two/CNV/', '/content/SNS_OCT_two/DME/', '/content/SNS_OCT_two/DRUSDEN/')\n",
        "X_test = np.array(load_Test_dataset(X_train[:len_test]))\n",
        "Y_test = np.array(Y_train[:len_test])\n",
        "X_train = X_train[len_test:]\n",
        "Y_train = Y_train[len_test:]"
      ],
      "metadata": {
        "id": "9vADKKT5jLS9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nd_epochs = 4\n",
        "batch_size = 5\n",
        "size_BD = len(X_train)\n",
        "steps_per_epochs = np.ceil(size_BD/batch_size)\n",
        "my_train_generator = batch_generator(batch_size,steps_per_epochs)"
      ],
      "metadata": {
        "id": "vvEA6zxljQgC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_OCT_two = Sequential()\n",
        "\n",
        "model_OCT_two.add(Conv2D(8,kernel_size=3,activation=\"relu\",input_shape = (800,800,1)))\n",
        "model_OCT_two.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model_OCT_two.add(Conv2D(16,kernel_size=3,activation=\"relu\"))\n",
        "model_OCT_two.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model_OCT_two.add(Conv2D(32,kernel_size=3,activation=\"relu\"))\n",
        "model_OCT_two.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model_OCT_two.add(Conv2D(64,kernel_size=3,activation=\"relu\"))\n",
        "model_OCT_two.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model_OCT_two.add(Conv2D(128,kernel_size=3,activation=\"relu\"))\n",
        "model_OCT_two.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model_OCT_two.add(Conv2D(256,kernel_size=3,activation=\"relu\"))\n",
        "model_OCT_two.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model_OCT_two.add(Conv2D(512,kernel_size=3,activation=\"relu\"))\n",
        "model_OCT_two.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model_OCT_two.add(Flatten())\n",
        "model_OCT_two.add(Dense(3,activation=\"softmax\"))"
      ],
      "metadata": {
        "id": "Ytm3W3KLjRq2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_OCT_two.compile(optimizer='adamax', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model_OCT_two.fit_generator(my_train_generator,steps_per_epoch=steps_per_epochs,epochs=nd_epochs,validation_data=(X_test,Y_test), use_multiprocessing=True)"
      ],
      "metadata": {
        "id": "GtIDeBuijTqS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.clear()\n",
        "Y_train.clear()\n",
        "X_test = []\n",
        "Y_test = []"
      ],
      "metadata": {
        "id": "YgrlviqojUtX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/SNS_MRI_two.zip"
      ],
      "metadata": {
        "id": "fYj3W8e_jVy6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len_test = 143\n",
        "X_train, Y_train = load_dataset('/content/SNS_MRI_two/glioma_tumor/', '/content/SNS_MRI_two/meningioma_tumor/', '/content/SNS_MRI_two/pituitary_tumor/')\n",
        "X_test = np.array(load_Test_dataset(X_train[:len_test]))\n",
        "Y_test = np.array(Y_train[:len_test])\n",
        "X_train = X_train[len_test:]\n",
        "Y_train = Y_train[len_test:]"
      ],
      "metadata": {
        "id": "w8R-gCKjjXHQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nd_epochs = 5\n",
        "batch_size = 5\n",
        "size_BD = len(X_train)\n",
        "steps_per_epochs = np.ceil(size_BD/batch_size)\n",
        "my_train_generator = batch_generator(batch_size,steps_per_epochs)"
      ],
      "metadata": {
        "id": "LhszIrShjYWD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_MRI_two = Sequential()\n",
        "\n",
        "model_MRI_two.add(Conv2D(8,kernel_size=3,activation=\"relu\",input_shape = (800,800,1)))\n",
        "model_MRI_two.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model_MRI_two.add(Conv2D(16,kernel_size=3,activation=\"relu\"))\n",
        "model_MRI_two.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model_MRI_two.add(Conv2D(32,kernel_size=3,activation=\"relu\"))\n",
        "model_MRI_two.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model_MRI_two.add(Conv2D(64,kernel_size=3,activation=\"relu\"))\n",
        "model_MRI_two.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model_MRI_two.add(Conv2D(128,kernel_size=3,activation=\"relu\"))\n",
        "model_MRI_two.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model_MRI_two.add(Conv2D(256,kernel_size=3,activation=\"relu\"))\n",
        "model_MRI_two.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model_MRI_two.add(Conv2D(512,kernel_size=3,activation=\"relu\"))\n",
        "model_MRI_two.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model_MRI_two.add(Flatten())\n",
        "model_MRI_two.add(Dense(3,activation=\"softmax\"))"
      ],
      "metadata": {
        "id": "3sguyOYHjZbm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_MRI_two.compile(optimizer='adamax', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model_MRI_two.fit_generator(my_train_generator,steps_per_epoch=steps_per_epochs,epochs=nd_epochs,validation_data=(X_test,Y_test), use_multiprocessing=True)"
      ],
      "metadata": {
        "id": "jHpw8DH7ja3P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.clear()\n",
        "Y_train.clear()\n",
        "X_test = []\n",
        "Y_test = []"
      ],
      "metadata": {
        "id": "PhSTrZiBjb7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/SNS_XRAY_two.zip"
      ],
      "metadata": {
        "id": "t9Jt4ZkSjdEe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len_test = 143\n",
        "X_train = []\n",
        "Y_train = []\n",
        "directory = '/content/SNS_XRAY_two/PNEUMONIA/'\n",
        "fil_array = os.listdir(directory)\n",
        "for fil in fil_array:\n",
        "  X_train.append(directory+fil)\n",
        "  if 'bacteria' in fil:\n",
        "    Y_train.append(0)\n",
        "  elif 'virus' in fil:\n",
        "    Y_train.append(1)\n",
        "X_test = np.array(load_Test_dataset(X_train[:len_test]))\n",
        "Y_test = np.array(Y_train[:len_test])\n",
        "X_train = X_train[len_test:]\n",
        "Y_train = Y_train[len_test:]"
      ],
      "metadata": {
        "id": "KenKFE_ojeDh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nd_epochs = 6\n",
        "batch_size = 5\n",
        "size_BD = len(X_train)\n",
        "steps_per_epochs = np.ceil(size_BD/batch_size)\n",
        "my_train_generator = batch_generator(batch_size,steps_per_epochs)"
      ],
      "metadata": {
        "id": "JhLbogPBjfnI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_XRAY_two = Sequential()\n",
        "\n",
        "model_XRAY_two.add(Conv2D(8,kernel_size=3,activation=\"relu\",input_shape = (800,800,1)))\n",
        "model_XRAY_two.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model_XRAY_two.add(Conv2D(16,kernel_size=3,activation=\"relu\"))\n",
        "model_XRAY_two.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model_XRAY_two.add(Conv2D(32,kernel_size=3,activation=\"relu\"))\n",
        "model_XRAY_two.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model_XRAY_two.add(Conv2D(64,kernel_size=3,activation=\"relu\"))\n",
        "model_XRAY_two.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model_XRAY_two.add(Conv2D(128,kernel_size=3,activation=\"relu\"))\n",
        "model_XRAY_two.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model_XRAY_two.add(Conv2D(256,kernel_size=3,activation=\"relu\"))\n",
        "model_XRAY_two.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model_XRAY_two.add(Conv2D(512,kernel_size=3,activation=\"relu\"))\n",
        "model_XRAY_two.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model_XRAY_two.add(Flatten())\n",
        "model_XRAY_two.add(Dense(2,activation=\"sigmoid\"))"
      ],
      "metadata": {
        "id": "J19GzBxJjgmn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_XRAY_two.compile(optimizer='adamax', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model_XRAY_two.fit_generator(my_train_generator,steps_per_epoch=steps_per_epochs,epochs=nd_epochs,validation_data=(X_test,Y_test), use_multiprocessing=True)"
      ],
      "metadata": {
        "id": "4plCTVMHjh_h"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}